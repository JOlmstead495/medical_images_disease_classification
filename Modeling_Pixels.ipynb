{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "np.set_printoptions(suppress=True)\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import re\n",
    "from sqlalchemy import create_engine\n",
    "import pickle\n",
    "\n",
    "##Sklearn (Model Imports)\n",
    "from sklearn.model_selection import train_test_split,KFold,StratifiedKFold,RandomizedSearchCV,GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve, f1_score\n",
    "from sklearn.metrics import accuracy_score, classification_report,roc_auc_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from Convert_To_Num import convert_wrapper,convert_series_to_float,convert_series_to_int"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull In Data From AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_aws = create_engine('postgresql://**ec2IP**/project03',echo=False)\n",
    "meta = MetaData(engine_aws)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create The Data Frame From AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col=[]\n",
    "for i in range(1,1801):\n",
    "    col=np.append(col,'P'+str(i))\n",
    "\n",
    "col=np.append(col,\"Class\")\n",
    "col = tuple(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = engine_aws.connect()\n",
    "pixel_data=Table('pixel_data',meta,autoload=True,schema='public')\n",
    "select_st = pixel_data.select()\n",
    "res = conn.execute(select_st)\n",
    "temp_list=[]\n",
    "count=0\n",
    "for _row in res:\n",
    "    count+=1\n",
    "    if count%1000==0:\n",
    "        print(count)\n",
    "    image_list=[]\n",
    "    image_list=np.append(image_list,np.array(list(_row[1])))\n",
    "    image_list=tuple(np.append(image_list,_row[2].lower()))\n",
    "    dict_temp={col[i]:image_list[i] for i in range(0,len(col))}\n",
    "    temp_list.append(dict_temp)\n",
    "    \n",
    "df=pd.DataFrame(temp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_wrapper(df,to_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pix=pd.get_dummies(df_pix,columns=['Class'],prefix='class',drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA\n",
    "1. Check number of classes (Normal v Drusen) - Good to start with\n",
    "2. Check the classification differences between Normal and Drusen - Does not look good.\n",
    "    - If quick modeling doesn't look good, will need to find new image processing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal    26565\n",
       "drusen     8866\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check number of classes\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Creation\n",
    "**Random Forest Worked Best**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up KFolds and Data For Model\n",
    "**Normal = True**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.get_dummies(df,columns=['Class'],prefix='class',drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(df['class_normal'])\n",
    "X = np.array(df.drop(columns=['class_normal']))\n",
    "kf = StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "1. Accuracy\n",
    "2. AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The score for Random Forest is\n",
      "Training:  99.49%\n",
      "Test set:  80.27%\n",
      "AUC Score For Random Forest: 85.52%\n",
      "AUC Score For Random Forest: 60.69%\n",
      "\n",
      "\n",
      "The score for Random Forest is\n",
      "Training:  99.40%\n",
      "Test set:  79.36%\n",
      "AUC Score For Random Forest: 84.36%\n",
      "AUC Score For Random Forest: 58.96%\n",
      "\n",
      "\n",
      "The score for Random Forest is\n",
      "Training:  99.51%\n",
      "Test set:  79.75%\n",
      "AUC Score For Random Forest: 83.81%\n",
      "AUC Score For Random Forest: 59.69%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=1400,min_samples_split=2,min_samples_leaf=1,max_features='auto',max_depth=40,bootstrap=False,n_jobs=-1)\n",
    "for train,test in kf.split(X,y):\n",
    "    forest.fit(X[train],y[train])\n",
    "    print(\"The score for Random Forest is\")\n",
    "    print(\"Training: {:6.2f}%\".format(100*forest.score(X[train], y[train])))\n",
    "    print(\"Test set: {:6.2f}%\".format(100*forest.score(X[test], y[test])))\n",
    "    pred_prob = forest.predict_proba(X[test])\n",
    "    pred = forest.predict(X[test])\n",
    "    print(\"AUC Score For Random Forest: {:0.2f}%\".format(100*roc_auc_score(y[test],pred_prob[:,1])))\n",
    "    print(\"AUC Score For Random Forest: {:0.2f}%\".format(100*roc_auc_score(y[test],pred)))\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest CV - Finds the Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 50 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 32.6min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed: 168.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=50, n_jobs=-1,\n",
       "          param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestClassifier(n_estimators=1400,min_samples_split=2,min_samples_leaf=1,max_features='auto',max_depth=40,bootstrap=False)\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, scoring='roc_auc', n_iter = 50, cv = 2, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1400,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 40,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Params\n",
    "{'n_estimators': 1400,\n",
    " 'min_samples_split': 2,\n",
    " 'min_samples_leaf': 1,\n",
    " 'max_features': 'auto',\n",
    " 'max_depth': 40,\n",
    " 'bootstrap': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(forest,open('RF_Pix_Model.p','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
